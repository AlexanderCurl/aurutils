#!/usr/bin/env python3
""" Rebuild AUR packages against newer dependencies
"""
import json
import fileinput
import sys
import os
import subprocess
import tempfile

from srcinfo.parse import parse_srcinfo
from decimal import Decimal
#from pyalpm import vercmp
from xdg import BaseDirectory

# Get the path to user-specific cache files
ARGV0 = 'sync-rebuild'
cache_dir = BaseDirectory.xdg_cache_home
aurdest = os.path.join(cache_dir, 'aurutils/sync')

if 'AURDEST' in os.environ:
    aurdest = os.getenv('AURDEST')


def run_readline(command, check=True):
    """Run the output from a command line-by-line.

    `aur` programs typically use newline delimited output. Here, this function
    is used with `aur repo` to read JSON objects, with each line representing
    one local repository package.

    """
    with subprocess.Popen(command, stdout=subprocess.PIPE) as process:
        while True:
            output = process.stdout.readline()
            if output == b'' and process.poll() is not None:
                break
            if output:
                yield output.strip()

        return_code = process.poll()
        if return_code > 0 and check:
            raise subprocess.CalledProcessError(return_code, command)


def srcinfo_get_version(srcinfo):
    """Return the full version string from a .SRCINFO file.

    The `epoch` key is optional, `pkgver` and `pkgrel` are assumed present.

    """
    with open(srcinfo, 'r', encoding='utf-8') as file:
        (data, errors) = parse_srcinfo(file.read())
        if errors:
            sys.exit(1)

        epoch  = data.get('epoch')
        pkgver = data['pkgver']
        pkgrel = data['pkgrel']

        if epoch is not None:
            return epoch + ':' + pkgver, pkgrel
        return pkgver, pkgrel


def increase_decimal(decimal_number, increment, n_digits=2):
    """Only increase the fractional part of a number.
    """
    # Convert the decimal number and increment to Decimal objects
    decimal_num = Decimal(str(decimal_number))
    inc = Decimal(str(increment))
    
    # Calculate the increased decimal
    increased_decimal = decimal_num + inc

    # Convert the increased decimal to a formatted string with fixed precision
    precision = '.' + str(n_digits) + 'f'
    increased_decimal_str = format(increased_decimal, precision)

    return increased_decimal_str


def update_pkgrel(buildscript, backup, pkgname, pkgrel=None, increment=0.1):
    """Update pkgrel in a PKGBUILD by a given increment.

    The original PKGBUILD is backed up before modification. Modifications assume
    a single caller and are not thread-safe.

    """
    n_digits = sum(ch.isdigit() for ch in str(increment).strip('0'))
    new_pkgrel = None

    with fileinput.input(buildscript, inplace=True, backup=backup) as finput:
        for line in finput:
            pkgrel_keyword = 'pkgrel='

            if line.startswith(pkgrel_keyword):
                # Extract and update the current pkgrel value
                if pkgrel is None:
                    pkgrel = float(line.split('=')[1])  # Only the last written pkgrel holds
                new_pkgrel = increase_decimal(pkgrel, increment, n_digits)

                # Replace the pkgrel value in the line
                line = f'{pkgrel_keyword}{new_pkgrel}\n'

            # Write the modified line to stdout (which redirects to the PKGBUILD file)
            print(line, end='')

    return new_pkgrel


# TODO: use vercmp to ensure rebuilds
# XXX: perform rebuilds in dependency order, abort reverse depends when depends fails (sync--ninja)
def rebuild_packages(repo_targets, db_name, fail_fast=False):
    """Rebuild a series of packages in succession
    """
    # TODO: user-specified build arguments (e.g. --chroot)
    build_cmd = ['aur', 'build', '-srn']

    if db_name is not None:
        build_cmd.extend(('--database', db_name))

    # Check that `pkgver` is consistent between local repository and .SRCINFO
    rebuilds = {}

    for pkgname, pkg in repo_targets.items():
        # Only run once per pkgbase
        if pkgname in rebuilds:
            continue

        # Retrieve metdata from local repository entry
        pkgbase = pkg['PackageBase']
        pkgver, pkgrel = pkg['Version'].rsplit('-', 1)

        # Retrieve metadata from .SRCINFO
        src_dir = os.path.join(aurdest, pkgbase)
        src_pkgver, _ = srcinfo_get_version(os.path.join(src_dir, '.SRCINFO'))

        # Set backup file for PKGBUILD
        buildscript = os.path.join(src_dir, 'PKGBUILD')
        backup = '.tmp'
        remove_backup = False

        # Increase subrelease level to avoid conflicts with intermediate
        # PKGBUILD updates
        if src_pkgver == pkgver:
            new_pkgrel = update_pkgrel(buildscript, backup, pkgname, pkgrel=float(pkgrel), increment=0.1)
            remove_backup = True

            # Print bumped pkgrel to standard error
            print(f'{ARGV0}: {pkgname}: {pkgver}-{pkgrel} -> {pkgver}-{new_pkgrel}', file=sys.stderr)
        else:
            print(f'{ARGV0}: source and local repository version differ', file=sys.stderr)
            print(f'{ARGV0}: using existing pkgver', file=sys.stderr)

        failed_rebuilds = {}

        # Build package with modified pkgrel
        try:
            subprocess.run(build_cmd, check=True, cwd=src_dir)

            # Build process completed successfully, remove backup PKGBUILD if it
            # was created above
            if remove_backup:
                os.remove(buildscript + backup)

        except subprocess.CalledProcessError:
            # Build process failed, revert to unmodified PKGBUILD
            print(f'{ARGV0}: {pkgbase}: build failed, reverting PKGBUILD', file=sys.stderr)
            os.replace(buildscript + backup, buildscript)

            # --fail-fast: if a package failed to build, also consider remaining targets as failed
            if fail_fast:
                print(f'{ARGV0}: {pkgbase}: build failed, exiting', file=sys.stderr)
                return rebuilds, list(set(repo_targets) - set(rebuilds))

            # Mark rebuild as failure for later reporting to the user
            failed_rebuilds[pkgname] = pkgbase

        rebuilds[pkgname] = pkgbase

        return rebuilds, failed_rebuilds


def print_cached_packages(args):
    """Print cached packages in `vercmp` order
    """
    name_args = ['--name=' + item for item in args]
    pacsift   = ['pacsift', *name_args, '--exact', '--cache']

    p1 = subprocess.Popen(pacsift, stdout=subprocess.PIPE, stderr=subprocess.DEVNULL)
    p2 = subprocess.Popen(['pacsort'], stdin=p1.stdout, stderr=subprocess.PIPE)
    p2.communicate()  # wait for the pipeline to finish


def main(targets, db_name, fail_fast, run_sync):
    # Ensure all sources are available. Only packages are cloned that are
    # already available in the local repository.
    sync_cmd = ['aur', 'sync', '--no-build', '--no-ver-argv']
    repo_cmd = ['aur', 'repo', '--jsonl']

    if db_name is not None:
        sync_cmd.extend(('--database', db_name))
        repo_cmd.extend(('--database', db_name))

    repo_targets = {}

    # Read repository contents line by line to handle potentially large databases
    for pkg_str in run_readline(repo_cmd):
        pkg = json.loads(pkg_str)
        pkgname = pkg['Name']

        # Restrict to packages specified on the command-line
        if pkgname in targets:
            repo_targets[pkgname] = {
                'PackageBase': pkg['PackageBase'], 'Version' : pkg['Version']
            }

    # Clone targets that are part of the local repository
    if len(repo_targets) > 0:
        sync_cmd.extend(list(repo_targets.keys()))

        if run_sync:
            repo_targets_ordered = {}  # `dict` preserves order since python >=3.6

            # Temporary file for dependency order
            with tempfile.NamedTemporaryFile() as sync_queue:
                sync_cmd.extend(['--save', sync_queue.name])

                # Clone AUR targets and retrieve dependency order. Dependencies
                # not in the local repository already will be added as targets.
                # XXX: requires at least one valid AUR target
                subprocess.run(sync_cmd, check=True)

                with open(sync_queue.name, 'r') as f:
                    for line in f.readlines():
                        name = os.path.basename(line.rstrip())
                        repo_targets_ordered[name] = repo_targets[name]

            # Local repository targets not retrieved by `aur-sync` are missing from AUR
            # XXX: append to queue if target directories are available
            not_aur = list(set(repo_targets.keys()) - set(repo_targets_ordered.keys()))
 
            # Build in dependency order
            rebuilds, failed = rebuild_packages(repo_targets_ordered, db_name, fail_fast)
        else:
            not_aur = []

            # Build in sequential (argument) order
            # XXX: support other directories than AURDEST
            rebuilds, failed = rebuild_packages(repo_targets, db_name, fail_fast)

        if len(not_aur) > 0:
            print(f'{ARGV0}: the following targets are not in AUR:', file=sys.stderr)
            print(' '.join(not_aur), file=sys.stderr)

        if len(failed) > 0:
            print(f'{ARGV0}: the following targets failed to build:', file=sys.stderr)
            print(' '.join(failed.keys()), file=sys.stderr)

        rest = list(set(targets) - set(rebuilds.keys()) - set(failed.keys()) - set(not_aur))
    else:
        rest = list(targets)

    if len(rest) > 0:
        print(f'{ARGV0}: the following targets are unavailable in the local repository',
              file=sys.stderr)
        print(' '.join(rest), file=sys.stderr)

        # Print any stale cached packages
        print(f'{ARGV0}: with cached entries:', file=sys.stderr)
        print_cached_packages(rest)


# Parse user arguments when run directly
if __name__ == '__main__':
    import argparse
    parser = argparse.ArgumentParser(prog=f'{ARGV0}', description='rebuild packages')
    parser.add_argument('-d', '--database')
    parser.add_argument('--fail-fast', action='store_true')
    parser.add_argument('--no-sync', action='store_false')
    parser.add_argument('targets', nargs='+')
    args = parser.parse_args()

    main({i:1 for i in args.targets}, args.database, args.fail_fast, args.no_sync)
